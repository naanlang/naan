/*
 * aws_s3.nlg
 * serviceAws
 *
 *     Access to S3 services for AWS.
 *
 * column positioning:                          //                          //                      !
 *
 * Copyright (c) 2020-2023 by Richard C. Zulch
 *
 */


/*
 * S3bucket
 * 
 * Bucket ooptions:
 *  {
 *      cacheControl: "max-age=2592000"         - default cache control, e.g. to "max-age=2592000"
 *  }
 *
 */

closure S3bucket(s3, name, bucketOptions, local bucket) {
    bucket = new(object, this)
    bucket.name = name

    //
    // head
    //
    bucket.head = closure head(key, local pending) {
        pending = new(nonce)
        s3.aws.headObject({
            Bucket: bucket.name
            Key: key
        }, function (error, data) {
            if error
                error = Error("S3bucket.head failed:", error.name, "key:", key, "in", bucket.name)
            pending.signal(list(error, data))
        })
        pending.wait()
    }

    //
    // listObjects
    //
    bucket.listObjects = closure listObjects(local pending) {
        pending = new(nonce)
        s3.aws.listObjectsV2({
            Bucket: bucket.name
        }, function (error, data) {
            if error
                error = Error("S3bucket.list failed:", error.name, "for", bucket.name)
            pending.signal(list(error, data))
        })
        pending.wait()
    }

    //
    // put
    //
    // options:
    //  {
    //      contentType: "text/plain"           - override contentType if specified
    //      cacheControl: "max-age=2592000"     - default cache control, e.g. to "max-age=2592000"
    //      metadata: { <items> }               - optional dictionary of keys to store
    //  }
    //
    bucket.put = closure put(key, data, options, local params, pending) {
        if !contentType
            contentType = "application/octet-stream"
        params = {
            Bucket: bucket.name
            Key: key
            ContentMD5: HashMD5_base64(data)
            Body: data
        }
        if options.contentType
            params.ContentType = options.contentType
        else
            params.ContentType = "application/octet-stream"
        if options.metadata
            params.Metadata = options.metadata
        if options.cacheControl
            params.CacheControl = options.cacheControl
        else if bucket.cacheControl
            params.CacheControl = bucket.cacheControl
        pending = new(nonce)
        s3.aws.putObject(params, function(error, resp) {
            if error
                error = Error("S3bucket.put failed:", error.name, "key:", key, "in", bucket.name)
            pending.signal(list(error, resp))
        })
        pending.wait()
    }

    // listMultipartUploads
    //
    // options:
    //  {
    //      keyMarker: <string>                 - start after this key
    //  }
    //
    bucket.listMultipartUploads = closure listMultipartUploads(prefix, options,
        local params, pending) {
        params = {
            Bucket: bucket.name
            Prefix: prefix
        }
        if options.keyMarker
            params.KeyMarker = options.keyMarker
        pending = new(nonce)
        s3.aws.listMultipartUploads(params, function(error, resp) {
            if error
                error = Error("S3bucket.listMultipartUploads failed:", error.name, "in", bucket.name)
            pending.signal(list(error, resp))
        })
        pending.wait()
    }

    // listParts
    //
    bucket.listParts = closure listParts(key, uploadID,
        local params, pending) {
        params = {
            Bucket: bucket.name
            Key: key
            UploadId: uploadID
        }
        pending = new(nonce)
        s3.aws.listParts(params, function(error, resp) {
            if error
                error = Error("S3bucket.listParts failed:", error.name, "key:", key, "in", bucket.name)
            pending.signal(list(error, resp))
        })
        pending.wait()
    }

    // createMultipartUpload
    //
    // options:
    //  {
    //      contentType:    <string>
    //      cacheControl:   <string>
    //      metadata:       { <items> }         - optional dictionary of keys to store
    //      acl:            <string>            - e.g. "public-read"
    //  }
    //
    bucket.createMultipartUpload = closure createMultipartUpload(key, options,
        local params, pending) {
        params = {
            Bucket: bucket.name
            Key: key
        }
        if options.contentType
            params.ContentType = options.contentType
        if options.cacheControl
            params.CacheControl = options.cacheControl
        if options.metadata
            params.Metadata = options.metadata
        if options.acl
            params.ACL = options.acl
        pending = new(nonce)
        s3.aws.createMultipartUpload(params, function(error, resp) {
            if error
                error = Error("S3bucket.createMultipartUpload failed:", error.name, "key:", key, "in", bucket.name)
            pending.signal(list(error, resp))
        })
        pending.wait()
    }

    // completeMultipartUpload
    //
    // parts:
    //  {
    //      [
    //          ChecksumSHA256: <string>
    //          ETag:           <string>
    //          PartNumber:     <integer>
    //      ]...
    //  }
    //
    bucket.completeMultipartUpload = closure completeMultipartUpload(key, uploadID, parts,
        local params, pending) {
        params = {
            Bucket: bucket.name
            Key: key
            UploadId: uploadID
            MultipartUpload: {
                Parts: parts
            }
        }
        pending = new(nonce)
        s3.aws.completeMultipartUpload(params, function(error, resp) {
            if error
                error = Error("S3bucket.completeMultipartUpload failed:", error.name, "key:", key, "in", bucket.name)
            pending.signal(list(error, resp))
        })
        pending.wait()
    }
    
    // abortMultipartUpload
    //
    bucket.abortMultipartUpload = closure abortMultipartUpload(key, uploadID,
        local params, pending) {
        params = {
            Bucket: bucket.name
            Key: key
            UploadId: uploadID
        }
        pending = new(nonce)
        s3.aws.abortMultipartUpload(params, function(error, resp) {
            if error
                error = Error("S3bucket.abortMultipartUpload failed:", error.name, "key:", key, "in", bucket.name)
            pending.signal(list(error, resp))
        })
        pending.wait()
    }

    // finis
    bucket
};


/*
 * S3
 *
 *     S3 access objects.
 *
 */

closure S3(local s3) {
    s3 = new(object, this)

    //
    // login
    //
    s3.login = closure login(creds, local params) {
        if !awsSDK
            return (list(Error("S3.login: no AWS SDK available")))
        params = { }
        if creds {
            params.region = creds.region
            params.credentials = {
                accessKeyId:        creds.keyID
                secretAccessKey:    creds.keySecret
            }
            if creds.endpoint
                params.endpoint = creds.endpoint
        }
        s3.aws = xnew(awsSDK.S3, params)
        if awsSDK.S3Client
            s3.client = xnew(awsSDK.S3Client, params)
        `(false, { ok: true })
    }
    
    //
    // bucket
    //
    //     Return a new bucket access object for the table of the specified name. The bucket may not 
    // yet exist; see S3bucket for methods.
    //
    s3.bucket = closure bucket(name) {
        S3bucket(s3, name)
    }
    
    //
    // getSignedURL
    //
    // This obtains a pre-signed URL for the specified command and its parameters. Options control
    // how the URL is generated.
    //
    // CommandParams:
    //  {
    //      Bucket:             <string>        // bucket name
    //      Key:                <string>        // object being operated upon
    //      ContentType:        <string>        // video/mp4 or whatever
    //      ResponseCacheControl:   <string>    // reportedly for getObject only
    //      ACL:                <string>        // e.g. "public-read"
    //      Body:               <data>          // fiik why you'd sign this
    //      PartNumber:         <integer>       // required for uploadPart
    //      UploadId:           <string>        // required for uploadPart
    //  }
    //
    // Options:
    //  {
    //      expiresIn:          <seconds>       // default expiration is 900 (15 minutes)
    //      signingDate:        <epoch-secs>    // reference time for URL being created
    //  }
    //
    s3.getSignedURL = closure getSignedURL(cmdname, cmdparams, options, local command, pending) {
        if s3.client {
            if cmdname == "putObject"
                cmdname = "PutObjectCommand"
            else if cmdname == "getObject"
                cmdname = "GetObjectCommand"
            else if cmdname == "uploadPart"
                cmdname = "UploadPartCommand"
            else
                return (list(Error("S3bucket.getSignedURL: command not present:", cmdname)))
            command = xnew(awsSDK.s3Commands[cmdname], cmdparams)
            await(awsSDK.getSignedUrl(s3.client, command, options))
        } else {
            debuglog("s3.getSignedURL: warning: old API")
            pending = new(nonce)
            if options.expiresIn {
                cmdparams = new(cmdparams)
                cmdparams.Expires = options.expiresIn
            }
            s3.aws.getSignedUrl(cmdname, cmdparams, function(error, data) {
                pending.signal(list(error, data))
            })
            pending.wait()
        }
    }

    // finis
    s3
};


/*
 * s3Init
 *
 *     Initialize the AWS module.
 *
 */

function s3Init(local manifest) {
    manifest = `(S3bucket, S3, s3Init)

    Naan.module.build(module.id, "aws_s3", function(modobj, compobj) {
        require("./serviceAws.nlg")
        compobj.manifest = manifest
        modobj.exports.S3 = S3
    })
} ();
